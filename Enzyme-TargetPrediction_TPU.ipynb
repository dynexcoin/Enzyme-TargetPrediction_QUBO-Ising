{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "aty_LiAEkfU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi"
      ],
      "metadata": {
        "id": "UPBGIEar4TRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem ,Descriptors, Draw\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "sznVhZM9kwrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Transformations.csv', encoding='latin1', nrows=1000)\n",
        "df1 = pd.read_csv('substances.csv', encoding='latin1', nrows=1000)\n",
        "df2 = pd.read_csv('metabolicdb.csv', encoding='latin1', nrows=1000)"
      ],
      "metadata": {
        "id": "Q2x6mzjVmRnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Predecessor_Name'] = df['Predecessor_Name'].astype(str)\n",
        "df['Successor_CID'] = df['Successor_CID'].astype(float)\n",
        "df1['SubstanceName'] = df1['SubstanceName'].astype(str)\n",
        "df1['PubChem_CID'] = df1['PubChem_CID'].astype(float)\n",
        "df2['substrate_cid'] = df2['substrate_cid'].astype(str)\n",
        "df2['prod_cid'] = df2['prod_cid'].astype(str)\n",
        "\n",
        "# First merge\n",
        "mergedDf1 = pd.merge(df, df1,\n",
        "                      left_on=['Successor_CID'],\n",
        "                      right_on=['PubChem_CID'],\n",
        "                      how='inner')\n",
        "\n",
        "# Second merge\n",
        "mergedDf = pd.merge(mergedDf1, df2,\n",
        "                     left_on=['Enzyme'],\n",
        "                     right_on=['enzyme'],\n",
        "                     how='inner')"
      ],
      "metadata": {
        "id": "_3wz-z8QnNfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "enzymeCounter = Counter()\n",
        "allPossiblePairs = set()\n",
        "allPossibleEnzymes = set()\n",
        "def updateSetsAndCounter(row):\n",
        "    enzymes = row['Enzyme'].split('; ')\n",
        "    enzymeCounter.update(enzymes)\n",
        "    allPossiblePairs.add((row['Predecessor_CID'], row['Successor_CID']))\n",
        "    allPossibleEnzymes.update(enzymes)\n",
        "mergedDf.apply(updateSetsAndCounter, axis=1)\n",
        "print(\"[INFO]: PHASE-1 DONE !\")\n",
        "\n",
        "enzymeFrequenciesDf = pd.DataFrame.from_dict(enzymeCounter, orient='index', columns=['Frequency']).reset_index()\n",
        "enzymeFrequenciesDf.rename(columns={'index': 'Enzyme'}, inplace=True)\n",
        "enzymeFrequenciesDf.sort_values(by='Frequency', ascending=False, inplace=True)\n",
        "print(\"[INFO]: PHASE-2 DONE !\")\n",
        "\n",
        "highFrequencyEnzymes = set(enzymeFrequenciesDf[enzymeFrequenciesDf['Frequency'] >= 10]['Enzyme'])\n",
        "print(\"[INFO]: PHASE-3 DONE !\")\n",
        "\n",
        "transformationEnzymeGroups = mergedDf.groupby(['Transformation', 'Enzyme']).size().reset_index(name='Counts')\n",
        "enzymeSpecificTransformationsSet = set(\n",
        "    transformationEnzymeGroups.groupby('Transformation')\n",
        "    .filter(lambda x: len(x) == 1)['Transformation'])\n",
        "print(\"[INFO]: PHASE-4 DONE !\")"
      ],
      "metadata": {
        "id": "dMmcdCXZnWOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def calculateWeights(row):\n",
        "    rowBasedWeight = 10 * (row['Enzyme'] in highFrequencyEnzymes)\n",
        "    rowBasedWeight += 5 * (row['Transformation'] in enzymeSpecificTransformationsSet)\n",
        "    rowBasedWeight += 3 * (row['Biosystem'] == 'Human')\n",
        "    return rowBasedWeight\n",
        "mergedDf['Row_Based_Weight'] = mergedDf.apply(calculateWeights, axis=1)\n",
        "print(\"[INFO]: PHASE-5 DONE !\")\n",
        "\n",
        "def calculateChemicalStructureWeight(inchi, smiles):\n",
        "    weight = 0\n",
        "    molInchi = Chem.MolFromInchi(inchi)\n",
        "    molSmiles = Chem.MolFromSmiles(smiles)\n",
        "    if molInchi and molSmiles:\n",
        "        mwInchi = Descriptors.MolWt(molInchi)\n",
        "        mwSmiles = Descriptors.MolWt(molSmiles)\n",
        "        fpInchi = Chem.RDKFingerprint(molInchi)\n",
        "        fpSmiles = Chem.RDKFingerprint(molSmiles)\n",
        "        tanimotoSimilarity = DataStructs.FingerprintSimilarity(fpInchi, fpSmiles)\n",
        "        weight = mwInchi * tanimotoSimilarity + mwSmiles\n",
        "    return weight\n",
        "print(\"[INFO]: PHASE-6 DONE !\")\n",
        "\n",
        "\n",
        "Q = defaultdict(int)\n",
        "N = 5 # at least have 5 pairs that catalyze with X enzyme\n",
        "\n",
        "# Updating Q Model (Dictionary) [Q: QUBO Model]\n",
        "def updateQ(row):\n",
        "    try:\n",
        "        enzymes = row['Enzyme'].split('; ')\n",
        "        target = row['Successor_CID']\n",
        "        predecessor = row['Predecessor_CID']\n",
        "        weight1 = row['Row_Based_Weight']\n",
        "        weight2 = calculateChemicalStructureWeight(row['InChI'], row['SMILES'])\n",
        "        totalWeight = weight1 + weight2\n",
        "        for enzyme in enzymes:\n",
        "            enzyme = enzyme.strip()\n",
        "            pair = f\"{enzyme}_{predecessor}_{target}\"\n",
        "            Q[(pair, pair)] += -totalWeight\n",
        "            for otherPredecessor, otherTarget in allPossiblePairs:\n",
        "                otherPair = f\"{enzyme}_{otherPredecessor}_{otherTarget}\"\n",
        "                Q[(pair, otherPair)] += 2 * N\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred finding in chemical informatics: {e}\")\n",
        "        print(f\"Skipping row: {row}\")\n",
        "mergedDf.apply(updateQ, axis=1)\n",
        "print(\"[INFO]: PHASE-7 DONE !\")"
      ],
      "metadata": {
        "id": "MyC3o3C1v_md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updatePairConstraint(predecessor, target):\n",
        "    pairsForThisReaction = [\n",
        "        f\"{enzyme.strip()}_{predecessor}_{target}\"\n",
        "        for enzyme in allPossibleEnzymes\n",
        "    ]\n",
        "    for i, pair1 in enumerate(pairsForThisReaction):\n",
        "        for j, pair2 in enumerate(pairsForThisReaction):\n",
        "            if i != j:\n",
        "                Q[(pair1, pair2)] -= 2  # EXPERIMENTAL::Encourage at least one enzyme to catalyze each (predecessor, target)\n",
        "print(\"[INFO]: PHASE-8 DONE !\")\n",
        "\n",
        "for predecessor, target in allPossiblePairs:\n",
        "    updatePairConstraint(predecessor, target)\n",
        "pairToIndex = {pair: i for i, pair in enumerate(allPossiblePairs)}\n",
        "enzymeToIndex = {enzyme: j for j, enzyme in enumerate(allPossibleEnzymes)}\n",
        "adjacencyMatrix = np.zeros((len(allPossiblePairs), len(allPossibleEnzymes)))\n",
        "def updateAdjacencyMatrix(pair, i):\n",
        "    for enzyme, j in enzymeToIndex.items():\n",
        "        pairStr = f\"{enzyme.strip()}_{pair[0]}_{pair[1]}\"\n",
        "        if (pairStr, pairStr) in Q:\n",
        "            adjacencyMatrix[i, j] = 1\n",
        "print(\"[INFO]: PHASE-9 DONE !\")\n",
        "\n",
        "for pair, i in pairToIndex.items():\n",
        "    updateAdjacencyMatrix(pair, i)\n",
        "def refineConstraints(adjacencyMatrix):\n",
        "    stronglyConnectedEnzymes = np.sum(adjacencyMatrix, axis=0) > 1\n",
        "    stronglyConnectedPairs = np.sum(adjacencyMatrix, axis=1) > 1\n",
        "    for pair, i in pairToIndex.items():\n",
        "        for enzyme, j in enzymeToIndex.items():\n",
        "            pairStr = f\"{enzyme.strip()}_{pair[0]}_{pair[1]}\"\n",
        "            qVal = Q.get((pairStr, pairStr), 0)\n",
        "            if qVal:\n",
        "                if stronglyConnectedEnzymes[j]:\n",
        "                    Q[(pairStr, pairStr)] = qVal * 1.5  # Increase by 50%\n",
        "                if stronglyConnectedPairs[i]:\n",
        "                    Q[(pairStr, pairStr)] = qVal * 1.5  # Increase by 50%\n",
        "\n",
        "refineConstraints(adjacencyMatrix)\n",
        "print(\"[INFO]: PHASE-10 DONE !\")"
      ],
      "metadata": {
        "id": "1R2gcKMbwD_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "allPossiblePairsList = list(allPossiblePairs)\n",
        "n = len(allPossiblePairsList)\n",
        "Q_np = np.array([[Q.get((allPossiblePairsList[i], allPossiblePairsList[j]), 0) for j in range(n)] for i in range(n)])\n",
        "Q_tpu = torch.tensor(Q_np, dtype=torch.float32, device=xm.xla_device())\n",
        "x = torch.rand(n, requires_grad=True, device=xm.xla_device())\n",
        "optimizer = torch.optim.SGD([x], lr=0.01)\n",
        "def roundTensor(tensor):\n",
        "    return torch.round(tensor)\n",
        "def objectiveFunction(x):\n",
        "    return torch.matmul(torch.matmul(x, Q_tpu), x.reshape(-1, 1))\n",
        "numEpochs = 10000\n",
        "for epoch in range(numEpochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss = objectiveFunction(x)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    with torch.no_grad():\n",
        "        x.data = roundTensor(x.data)\n",
        "result = x.cpu().detach().numpy()\n",
        "reverseIndexMapping = {i: '_'.join(map(str, pair)) for pair, i in pairToIndex.items()}\n",
        "optimalPairs = [reverseIndexMapping[i] for i, value in enumerate(result) if value == 1]"
      ],
      "metadata": {
        "id": "wZSNaI2CoV0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimalTransformations = {}\n",
        "for pair in optimalPairs:\n",
        "    print(f\"Pair: {pair}\")\n",
        "    predecessor, target = pair.split('_')\n",
        "    predQuery = df1.loc[df1['PubChem_CID'] == int(predecessor), 'SMILES']\n",
        "    targetQuery = df1.loc[df1['PubChem_CID'] == float(target), 'SMILES']\n",
        "    predecessorSmiles = predQuery.iloc[0] if not predQuery.empty else 'Not Found'\n",
        "    targetSmiles = targetQuery.iloc[0] if not targetQuery.empty else 'Not Found'\n",
        "    optimalTransformations[predecessorSmiles] = targetSmiles\n",
        "\n",
        "    #print(f\"Optimal transformation: {predecessorSmiles} -> {targetSmiles}\")"
      ],
      "metadata": {
        "id": "zan_CXtapqrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Visualize(predecessorSmiles):\n",
        "    targetSmiles = optimalTransformations.get(predecessorSmiles, \"Not found\")\n",
        "    if targetSmiles == \"Not found\":\n",
        "        print(\"Predecessor SMILES not found in the optimal transformations.\")\n",
        "        return\n",
        "    # Drawing predecessor molecule\n",
        "    predMol = Chem.MolFromSmiles(predecessorSmiles)\n",
        "    predImg = Draw.MolToMPL(predMol, size=(300, 300), kekulize=True)\n",
        "    plt.title(\"Predecessor Molecule\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Drawing target molecule\n",
        "    targetMol = Chem.MolFromSmiles(targetSmiles)\n",
        "    targetImg = Draw.MolToMPL(targetMol, size=(300, 300), kekulize=True)\n",
        "    plt.title(\"Predicted Target Molecule\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "predecessorSmiles = \"C[C@]12CCC(=O)C=C1CC[C@H]1[C@@H]3CC[C@@H]([C@@]3(C)CC[C@H]21)O\" # EXAMPLE\n",
        "Visualize(predecessorSmiles)"
      ],
      "metadata": {
        "id": "e7hCooVHp_Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNrtFqSLvclp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}